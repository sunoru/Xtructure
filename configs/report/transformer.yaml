name: report-transformer
description: Transformer with NMM std data
task: iam2structure
model: transformer

learning-rate: 0.001
batch-size: 128
epochs: 2
logging-period: 40
checkpoints: ../../checkpoints
output-dir: ../../output

vocab-size: 20
embedding-size: 128
max-threads: 14
bonds-loss: sqr
pre-train: yes

network:
  num-encoders: 2
  num-decoders: 2
  window-size: 18

data:
  - mat: ../../data/Norm_Stand_NMM_DFTion_IAM_coherent_patterns.mat
    data-key: std_pattern
    bonds: ../../data/NMM.bonds
    train: 0-159999
    test: 160000-173996

